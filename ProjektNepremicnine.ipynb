{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8c4f97",
   "metadata": {},
   "source": [
    "### Linear regression with log-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be925f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: 229129.89412348837\n",
      "Mean Squared Error: 0.3243280488925497\n",
      "R-squared: 0.4146675840007449\n",
      "Mean Absolute Error: 0.4296943468817331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price(propType, livingSize, year, regija):\n",
    "    # Encode categorical features\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    # Scale numerical features\n",
    "    livingSize_log = np.log1p(livingSize)  # Apply log transformation to livingSize\n",
    "    year_log = np.log1p(year)\n",
    "    \n",
    "    # Make predictions using the trained model\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Stanovanje'\n",
    "user_livingSize = 50  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Dolenjska'\n",
    "\n",
    "# Predict log-transformed price based on user input\n",
    "predicted_log_price = predict_log_price(user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price = np.expm1(predicted_log_price)\n",
    "\n",
    "print(f'Predicted Price: {predicted_price}')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e171b",
   "metadata": {},
   "source": [
    "### Removing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47840571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: 235326.71753721792\n",
      "Mean Squared Error: 0.2982527724275919\n",
      "R-squared: 0.42030856323504096\n",
      "Mean Absolute Error: 0.4138075694517879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Define a function to remove outliers based on Z-scores\n",
    "def remove_outliers_zscore(df, column, threshold=4):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    df = df[(z_scores < threshold)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers from 'Price_Per_Sqm' column\n",
    "df = remove_outliers_zscore(df, 'year', 3)\n",
    "df = remove_outliers_zscore(df, 'Price_Per_Sqm', 3)\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price(propType, livingSize, year, regija):\n",
    "    # Encode categorical features\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    # Scale numerical features\n",
    "    livingSize_log = np.log1p(livingSize)  # Apply log transformation to livingSize\n",
    "    year_log = np.log1p(year)\n",
    "    \n",
    "    # Make predictions using the trained model\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Stanovanje'\n",
    "user_livingSize = 50  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Dolenjska'\n",
    "\n",
    "# Predict log-transformed price based on user input\n",
    "predicted_log_price = predict_log_price(user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price = np.expm1(predicted_log_price)\n",
    "\n",
    "print(f'Predicted Price: {predicted_price}')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f45eb",
   "metadata": {},
   "source": [
    "### Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb89ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: 116000.0000000001\n",
      "Mean Squared Error: 0.31818931887188046\n",
      "R-squared: 0.38155940037444513\n",
      "Mean Absolute Error: 0.3710976277917724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Define a function to remove outliers based on Z-scores\n",
    "def remove_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    df = df[(z_scores < threshold)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers from 'Price_Per_Sqm' column\n",
    "df = remove_outliers_zscore(df, 'year', 3)\n",
    "df = remove_outliers_zscore(df, 'Price_Per_Sqm', 3)\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a Decision Tree model\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price(propType, livingSize, year, regija):\n",
    "    # Encode categorical features\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    # Scale numerical features\n",
    "    livingSize_log = np.log1p(livingSize)  # Apply log transformation to livingSize\n",
    "    year_log = np.log1p(year)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Stanovanje'\n",
    "user_livingSize = 50  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Dolenjska'\n",
    "\n",
    "# Predict log-transformed price based on user input\n",
    "predicted_log_price = predict_log_price(user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price = np.expm1(predicted_log_price)\n",
    "\n",
    "print(f'Predicted Price: {predicted_price}')\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88f9fc",
   "metadata": {},
   "source": [
    "### Random Forrest regression and Gradient Booster regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6e7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predicted Price: 142696.54774545555\n",
      "Gradient Boosting Predicted Price: 171307.77846271315\n",
      "\n",
      "Random Forest Model Metrics:\n",
      "Mean Squared Error: 0.1797247614846413\n",
      "R-squared: 0.650682525566247\n",
      "Mean Absolute Error: 0.2888203509810451\n",
      "\n",
      "Gradient Boosting Model Metrics:\n",
      "Mean Squared Error: 0.17656912732191696\n",
      "R-squared: 0.6568158938726166\n",
      "Mean Absolute Error: 0.30052425225632295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Define a function to remove outliers based on Z-scores\n",
    "def remove_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    df = df[(z_scores < threshold)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers from 'Price_Per_Sqm' column\n",
    "df = remove_outliers_zscore(df, 'year', 3)\n",
    "df = remove_outliers_zscore(df, 'Price_Per_Sqm', 3)\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a Random Forest model\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gradient_boosting_model = GradientBoostingRegressor(random_state=42)\n",
    "gradient_boosting_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price(model, propType, livingSize, year, regija):\n",
    "    # Encode categorical features\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    # Scale numerical features\n",
    "    livingSize_log = np.log1p(livingSize)  # Apply log transformation to livingSize\n",
    "    year_log = np.log1p(year)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Stanovanje'\n",
    "user_livingSize = 50  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Dolenjska'\n",
    "\n",
    "# Predict log-transformed price based on user input using Random Forest model\n",
    "predicted_log_price_rf = predict_log_price(random_forest_model, user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Predict log-transformed price based on user input using Gradient Boosting model\n",
    "predicted_log_price_gb = predict_log_price(gradient_boosting_model, user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log prices back to the original scale\n",
    "predicted_price_rf = np.expm1(predicted_log_price_rf)\n",
    "predicted_price_gb = np.expm1(predicted_log_price_gb)\n",
    "\n",
    "print(f'Random Forest Predicted Price: {predicted_price_rf}')\n",
    "print(f'Gradient Boosting Predicted Price: {predicted_price_gb}')\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "y_pred_rf = random_forest_model.predict(X_test_scaled)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print('\\nRandom Forest Model Metrics:')\n",
    "print(f'Mean Squared Error: {mse_rf}')\n",
    "print(f'R-squared: {r2_rf}')\n",
    "print(f'Mean Absolute Error: {mae_rf}')\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "y_pred_gb = gradient_boosting_model.predict(X_test_scaled)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "\n",
    "print('\\nGradient Boosting Model Metrics:')\n",
    "print(f'Mean Squared Error: {mse_gb}')\n",
    "print(f'R-squared: {r2_gb}')\n",
    "print(f'Mean Absolute Error: {mae_gb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b99e68",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5dfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Predicted Price: 156815.28789783764\n",
      "\n",
      "SVR Model Metrics:\n",
      "Mean Squared Error: 0.22157975057186713\n",
      "R-squared: 0.5693321375639158\n",
      "Mean Absolute Error: 0.33142423962327966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Define a function to remove outliers based on Z-scores\n",
    "def remove_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    df = df[(z_scores < threshold)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers from 'Price_Per_Sqm' column\n",
    "df = remove_outliers_zscore(df, 'year', 3)\n",
    "df = remove_outliers_zscore(df, 'Price_Per_Sqm', 3)\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a Support Vector Regression model\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price(model, propType, livingSize, year, regija):\n",
    "    # Encode categorical features\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    # Scale numerical features\n",
    "    livingSize_log = np.log1p(livingSize)  # Apply log transformation to livingSize\n",
    "    year_log = np.log1p(year)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Stanovanje'\n",
    "user_livingSize = 50  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Dolenjska'\n",
    "\n",
    "# Predict log-transformed price based on user input using SVR model\n",
    "predicted_log_price_svr = predict_log_price(svr_model, user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price_svr = np.expm1(predicted_log_price_svr)\n",
    "\n",
    "print(f'SVR Predicted Price: {predicted_price_svr}')\n",
    "\n",
    "# Evaluate the SVR model\n",
    "y_pred_svr = svr_model.predict(X_test_scaled)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "\n",
    "print('\\nSVR Model Metrics:')\n",
    "print(f'Mean Squared Error: {mse_svr}')\n",
    "print(f'R-squared: {r2_svr}')\n",
    "print(f'Mean Absolute Error: {mae_svr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1a184",
   "metadata": {},
   "source": [
    "### Cross validation for 3 models - NOT USEFUL SKIP THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7deb421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Regression Model Metrics:\n",
      "Mean Squared Error (CV): 0.3311355308047916\n",
      "Mean Squared Error (Test): 0.31818931887188046\n",
      "R-squared: 0.38155940037444513\n",
      "Mean Absolute Error: 0.3710976277917724\n",
      "Predicted Price (user input): 191000.00000000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Regression Model Metrics:\n",
      "Mean Squared Error (CV): 0.19235051028861655\n",
      "Mean Squared Error (Test): 0.1797247614846413\n",
      "R-squared: 0.650682525566247\n",
      "Mean Absolute Error: 0.2888203509810451\n",
      "Predicted Price (user input): 187412.2751329893\n",
      "\n",
      "SVR Model Metrics:\n",
      "Mean Squared Error (CV): 0.2183289349134306\n",
      "Mean Squared Error (Test): 0.22157975057186713\n",
      "R-squared: 0.5693321375639158\n",
      "Mean Absolute Error: 0.33142423962327966\n",
      "Predicted Price (user input): 187977.87752563364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Define a function to remove outliers based on Z-scores\n",
    "def remove_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    df = df[(z_scores < threshold)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers from 'Price_Per_Sqm' column\n",
    "df = remove_outliers_zscore(df, 'year', 3)\n",
    "df = remove_outliers_zscore(df, 'Price_Per_Sqm', 3)\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Decision Tree Regression with Cross-validation\n",
    "decision_tree_model = DecisionTreeRegressor(random_state=42)\n",
    "cv_scores_dt = cross_val_score(decision_tree_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_dt = -cv_scores_dt.mean()\n",
    "\n",
    "# Fit the Decision Tree model on the entire training set\n",
    "decision_tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price(model, propType, livingSize, year, regija):\n",
    "    # Encode categorical features\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    # Scale numerical features\n",
    "    livingSize_log = np.log1p(livingSize)  # Apply log transformation to livingSize\n",
    "    year_log = np.log1p(year)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Stanovanje'\n",
    "user_livingSize = 50  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Ljubljana-okolica'\n",
    "\n",
    "# Predict log-transformed price based on user input using Decision Tree model\n",
    "predicted_log_price_dt = predict_log_price(decision_tree_model, user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price_dt = np.expm1(predicted_log_price_dt)\n",
    "\n",
    "# Evaluate Decision Tree Regression model on the test set\n",
    "y_pred_dt = decision_tree_model.predict(X_test_scaled)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "\n",
    "print('\\nDecision Tree Regression Model Metrics:')\n",
    "print(f'Mean Squared Error (CV): {cv_mse_dt}')\n",
    "print(f'Mean Squared Error (Test): {mse_dt}')\n",
    "print(f'R-squared: {r2_dt}')\n",
    "print(f'Mean Absolute Error: {mae_dt}')\n",
    "print(f'Predicted Price (user input): {predicted_price_dt}')\n",
    "\n",
    "# RandomForestRegressor with Cross-validation\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "cv_scores_rf = cross_val_score(random_forest_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_rf = -cv_scores_rf.mean()\n",
    "\n",
    "# Fit the Random Forest model on the entire training set\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict log-transformed price based on user input using Random Forest model\n",
    "predicted_log_price_rf = predict_log_price(random_forest_model, user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price_rf = np.expm1(predicted_log_price_rf)\n",
    "\n",
    "# Evaluate Random Forest Regression model on the test set\n",
    "y_pred_rf = random_forest_model.predict(X_test_scaled)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print('\\nRandom Forest Regression Model Metrics:')\n",
    "print(f'Mean Squared Error (CV): {cv_mse_rf}')\n",
    "print(f'Mean Squared Error (Test): {mse_rf}')\n",
    "print(f'R-squared: {r2_rf}')\n",
    "print(f'Mean Absolute Error: {mae_rf}')\n",
    "print(f'Predicted Price (user input): {predicted_price_rf}')\n",
    "\n",
    "# SVR with Cross-validation\n",
    "svr_model = SVR()\n",
    "cv_scores_svr = cross_val_score(svr_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_svr = -cv_scores_svr.mean()\n",
    "\n",
    "# Fit the SVR model on the entire training set\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict log-transformed price based on user input using SVR model\n",
    "predicted_log_price_svr = predict_log_price(svr_model, user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price_svr = np.expm1(predicted_log_price_svr)\n",
    "\n",
    "# Evaluate SVR model on the test set\n",
    "y_pred_svr = svr_model.predict(X_test_scaled)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "\n",
    "print('\\nSVR Model Metrics:')\n",
    "print(f'Mean Squared Error (CV): {cv_mse_svr}')\n",
    "print(f'Mean Squared Error (Test): {mse_svr}')\n",
    "print(f'R-squared: {r2_svr}')\n",
    "print(f'Mean Absolute Error: {mae_svr}')\n",
    "print(f'Predicted Price (user input): {predicted_price_svr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff094332",
   "metadata": {},
   "source": [
    "### Hyperparemetrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c74d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     51\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Get the best parameters\u001b[39;00m\n\u001b[0;32m     55\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Remove outliers\n",
    "df = remove_outliers_zscore(df, 'year', 3)\n",
    "df = remove_outliers_zscore(df, 'Price_Per_Sqm', 3)\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest model with hyperparameter tuning using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_params)\n",
    "best_rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price_rf(propType, livingSize, year, regija):\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    livingSize_log = np.log1p(livingSize)\n",
    "    year_log = np.log1p(year)\n",
    "\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = best_rf_model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Stanovanje'\n",
    "user_livingSize = 50  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Dolenjska'\n",
    "\n",
    "# Predict log-transformed price based on user input\n",
    "predicted_log_price_rf = predict_log_price_rf(user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price_rf = np.expm1(predicted_log_price_rf)\n",
    "\n",
    "print(f'Random Forest Predicted Price: {predicted_price_rf}')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_rf = best_rf_model.predict(X_test_scaled)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Random Forest Mean Squared Error: {mse_rf}')\n",
    "print(f'Random Forest R-squared: {r2_rf}')\n",
    "print(f'Random Forest Mean Absolute Error: {mae_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e27960",
   "metadata": {},
   "source": [
    "### Random Forrest with the best hyperparametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14990040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predicted Price: 429330.5255122348\n",
      "Random Forest Mean Squared Error: 0.17546161086033804\n",
      "Random Forest R-squared: 0.6589684901540456\n",
      "Random Forest Mean Absolute Error: 0.2902934257310538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokzu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Data integration\n",
    "df = pd.read_excel('podatkiZaPython.xlsx')\n",
    "\n",
    "# Apply log transformations\n",
    "df['Log_Price'] = np.log1p(df['price'])\n",
    "df['Log_LivingSize'] = np.log1p(df['livingSize'])\n",
    "df['Log_Year'] = np.log1p(df['year'])\n",
    "\n",
    "# Calculate price per square meter\n",
    "df['Price_Per_Sqm'] = df['price'] / df['livingSize']\n",
    "\n",
    "# Define a function to remove outliers based on Z-scores\n",
    "def remove_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    df = df[(z_scores < threshold)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers\n",
    "df = remove_outliers_zscore(df, 'year', 3)\n",
    "df = remove_outliers_zscore(df, 'Price_Per_Sqm', 3)\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "le_propType = LabelEncoder()\n",
    "le_regija = LabelEncoder()\n",
    "df['propType'] = le_propType.fit_transform(df['propType'])\n",
    "df['regija'] = le_regija.fit_transform(df['regija'])\n",
    "\n",
    "# Feature selection\n",
    "features = ['propType', 'Log_LivingSize', 'Log_Year', 'regija']\n",
    "X = df[features]\n",
    "y = df['Log_Price']  # Use log-transformed price as the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Best hyperparameters obtained from the grid search\n",
    "best_hyperparameters = {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_hyperparameters)\n",
    "best_rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to predict log-transformed price based on user input\n",
    "def predict_log_price_rf(propType, livingSize, year, regija):\n",
    "    propType_encoded = le_propType.transform([propType])[0]\n",
    "    regija_encoded = le_regija.transform([regija])[0]\n",
    "\n",
    "    livingSize_log = np.log1p(livingSize)\n",
    "    year_log = np.log1p(year)\n",
    "\n",
    "    input_features = scaler.transform([[propType_encoded, livingSize_log, year_log, regija_encoded]])\n",
    "    predicted_log_price = best_rf_model.predict(input_features)\n",
    "\n",
    "    return predicted_log_price[0]\n",
    "\n",
    "#Ljubljana-mesto\n",
    "#Severna-primorska\n",
    "#Savinjska\n",
    "#Juna-primorska\n",
    "#Ljubljana-okolica\n",
    "#Gorenjska\n",
    "#Dolenjska\n",
    "#Posavska\n",
    "#Notranjska\n",
    "#Podravska\n",
    "#Koroka\n",
    "#Pomurska\n",
    "#Zasavska\n",
    "\n",
    "# Example user input (replace with actual values)\n",
    "user_propType = 'Hia'\n",
    "user_livingSize = 150  # Replace with actual value\n",
    "user_year = 2020  # Replace with actual value\n",
    "user_regija = 'Gorenjska'\n",
    "\n",
    "# Predict log-transformed price based on user input\n",
    "predicted_log_price_rf = predict_log_price_rf(user_propType, user_livingSize, user_year, user_regija)\n",
    "\n",
    "# Convert the predicted log price back to the original scale\n",
    "predicted_price_rf = np.expm1(predicted_log_price_rf)\n",
    "\n",
    "print(f'Random Forest Predicted Price: {predicted_price_rf}')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_rf = best_rf_model.predict(X_test_scaled)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Random Forest Mean Squared Error: {mse_rf}')\n",
    "print(f'Random Forest R-squared: {r2_rf}')\n",
    "print(f'Random Forest Mean Absolute Error: {mae_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3a11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
